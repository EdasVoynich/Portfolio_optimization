{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for 2024-02-12 with starttime 45334...\n",
      "Scraping data for 2024-02-13 with starttime 45335...\n",
      "Scraping data for 2024-02-14 with starttime 45336...\n",
      "Scraping data for 2024-02-15 with starttime 45337...\n",
      "Scraping data for 2024-02-16 with starttime 45338...\n",
      "Scraping data for 2024-02-17 with starttime 45339...\n",
      "Scraping data for 2024-02-18 with starttime 45340...\n",
      "Scraping data for 2024-02-19 with starttime 45341...\n",
      "Scraping data for 2024-02-20 with starttime 45342...\n",
      "Scraping data for 2024-02-21 with starttime 45343...\n",
      "Scraping data for 2024-02-22 with starttime 45344...\n",
      "Scraping data for 2024-02-23 with starttime 45345...\n",
      "Scraping data for 2024-02-24 with starttime 45346...\n",
      "Scraping data for 2024-02-25 with starttime 45347...\n",
      "Scraping data for 2024-02-26 with starttime 45348...\n",
      "Scraping data for 2024-02-27 with starttime 45349...\n",
      "Scraping data for 2024-02-28 with starttime 45350...\n",
      "Scraping data for 2024-02-29 with starttime 45351...\n",
      "Scraping data for 2024-03-01 with starttime 45352...\n",
      "Scraping data for 2024-03-02 with starttime 45353...\n",
      "Scraping data for 2024-03-03 with starttime 45354...\n",
      "Scraping data for 2024-03-04 with starttime 45355...\n",
      "Scraping data for 2024-03-05 with starttime 45356...\n",
      "Scraping data for 2024-03-06 with starttime 45357...\n",
      "Scraping data for 2024-03-07 with starttime 45358...\n",
      "Scraping data for 2024-03-08 with starttime 45359...\n",
      "Scraping data for 2024-03-09 with starttime 45360...\n",
      "Scraping data for 2024-03-10 with starttime 45361...\n",
      "Scraping data for 2024-03-11 with starttime 45362...\n",
      "Scraping data for 2024-03-12 with starttime 45363...\n",
      "Scraping data for 2024-03-13 with starttime 45364...\n",
      "Scraping data for 2024-03-14 with starttime 45365...\n",
      "Scraping data for 2024-03-15 with starttime 45366...\n",
      "Scraping data for 2024-03-16 with starttime 45367...\n",
      "Scraping data for 2024-03-17 with starttime 45368...\n",
      "Scraping data for 2024-03-18 with starttime 45369...\n",
      "Scraping data for 2024-03-19 with starttime 45370...\n",
      "Scraping data for 2024-03-20 with starttime 45371...\n",
      "Scraping data for 2024-03-21 with starttime 45372...\n",
      "Scraping data for 2024-03-22 with starttime 45373...\n",
      "Scraping data for 2024-03-23 with starttime 45374...\n",
      "Scraping data for 2024-03-24 with starttime 45375...\n",
      "Scraping data for 2024-03-25 with starttime 45376...\n",
      "Scraping data for 2024-03-26 with starttime 45377...\n",
      "Scraping data for 2024-03-27 with starttime 45378...\n",
      "Scraping data for 2024-03-28 with starttime 45379...\n",
      "Scraping data for 2024-03-29 with starttime 45380...\n",
      "Scraping data for 2024-03-30 with starttime 45381...\n",
      "Scraping data for 2024-03-31 with starttime 45382...\n",
      "Scraping data for 2024-04-01 with starttime 45383...\n",
      "Scraping data for 2024-04-02 with starttime 45384...\n",
      "Scraping data for 2024-04-03 with starttime 45385...\n",
      "Scraping data for 2024-04-04 with starttime 45386...\n",
      "Scraping data for 2024-04-05 with starttime 45387...\n",
      "Scraping data for 2024-04-06 with starttime 45388...\n",
      "Scraping data for 2024-04-07 with starttime 45389...\n",
      "Scraping data for 2024-04-08 with starttime 45390...\n",
      "Scraping data for 2024-04-09 with starttime 45391...\n",
      "Scraping data for 2024-04-10 with starttime 45392...\n",
      "Scraping data for 2024-04-11 with starttime 45393...\n",
      "Scraping data for 2024-04-12 with starttime 45394...\n",
      "Scraping data for 2024-04-13 with starttime 45395...\n",
      "Scraping data for 2024-04-14 with starttime 45396...\n",
      "Scraping data for 2024-04-15 with starttime 45397...\n",
      "Scraping data for 2024-04-16 with starttime 45398...\n",
      "Scraping data for 2024-04-17 with starttime 45399...\n",
      "Scraping data for 2024-04-18 with starttime 45400...\n",
      "Scraping data for 2024-04-19 with starttime 45401...\n",
      "Scraping data for 2024-04-20 with starttime 45402...\n",
      "Scraping data for 2024-04-21 with starttime 45403...\n",
      "Scraping data for 2024-04-22 with starttime 45404...\n",
      "Scraping data for 2024-04-23 with starttime 45405...\n",
      "Scraping data for 2024-04-24 with starttime 45406...\n",
      "Scraping data for 2024-04-25 with starttime 45407...\n",
      "Scraping data for 2024-04-26 with starttime 45408...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_starttime(start_date):\n",
    "    # Placeholder function to calculate the initial starttime value based on a known mapping\n",
    "    # This calculation needs to be adjusted based on the actual mapping logic\n",
    "    # For example, if you know the starttime value for a specific date, calculate the offset from start_date\n",
    "    known_date = datetime(2024, 1, 1)\n",
    "    known_starttime_value = 45292  # Known starttime value for the known_date\n",
    "    delta_days = (start_date - known_date).days\n",
    "    return known_starttime_value + delta_days\n",
    "\n",
    "def scrape_archives(start_date, end_date):\n",
    "    base_url = \"https://economictimes.indiatimes.com\"\n",
    "    current_date = start_date\n",
    "    starttime = get_starttime(start_date)\n",
    "    while current_date <= end_date:\n",
    "        print(f\"Scraping data for {current_date.strftime('%Y-%m-%d')} with starttime {starttime}...\")\n",
    "        url = f\"{base_url}/archivelist/year-{current_date.year},month-{current_date.month},starttime-{starttime}.cms\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            articles = soup.find_all('a', href=True)\n",
    "            data = []\n",
    "            for article in articles:\n",
    "                if '/articleshow/' in article['href']:\n",
    "                    title = article.text.strip()\n",
    "                    link = base_url + article['href']\n",
    "                    data.append({'title': title, 'link': link, 'date': current_date.strftime('%Y-%m-%d')})\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(f'data/ET_Archives_{current_date.strftime(\"%Y-%m-%d\")}.csv', index=False)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        current_date += timedelta(days=1)\n",
    "        starttime += 1  # Increment starttime for the next day\n",
    "\n",
    "# Define the date range for the last 10 years\n",
    "end_date = datetime.today()\n",
    "start_date = datetime(2024, 2, 12)\n",
    "\n",
    "# Scrape archives\n",
    "scrape_archives(start_date, end_date)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
